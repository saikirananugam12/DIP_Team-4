{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESP_9F3qFk-H",
        "outputId": "408d8b26-5aac-472b-9bd2-aaee64a67f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "csv_path = '/content/drive/MyDrive/Lectures/fairface_filtered_10000.csv'\n",
        "images_folder = '/content/drive/MyDrive/Lectures/Train select/'\n"
      ],
      "metadata": {
        "id": "IZ74No2ZIkiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# Inspect the first few rows and column names\n",
        "print(\"Columns in CSV:\", data.columns)\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvURQ48xIsGK",
        "outputId": "45002b33-79be-4a1e-97be-b8d700cfb722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in CSV: Index(['file', 'age', 'gender', 'race', 'service_test'], dtype='object')\n",
            "    file  age  gender  race  service_test\n",
            "0  27327    1       1     2         False\n",
            "1  63584    0       0     1         False\n",
            "2  35860    6       0     4          True\n",
            "3  83767    4       1     2          True\n",
            "4  66866    1       0     3         False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'file' column to strings\n",
        "data['file'] = data['file'].astype(str)\n",
        "\n",
        "# Remove extra spaces if any\n",
        "data['file'] = data['file'].str.strip()\n",
        "\n",
        "# Correct file names by replacing '.jpg.jpg' with '.jpg'\n",
        "data['file'] = data['file'].str.replace('.jpg.jpg', '.jpg', regex=False)\n",
        "\n",
        "# Display a few updated file names\n",
        "print(\"Updated file names in CSV:\")\n",
        "print(data['file'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yHKPvizJEvN",
        "outputId": "b833688c-0c8c-411b-a694-0410a2b72120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated file names in CSV:\n",
            "0    27327\n",
            "1    63584\n",
            "2    35860\n",
            "3    83767\n",
            "4    66866\n",
            "Name: file, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# List the first few files in the folder\n",
        "image_files = os.listdir(images_folder)\n",
        "print(f\"Sample files in folder: {image_files[:10]}\")\n",
        "print(f\"Number of files in folder: {len(image_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VSARlwZJHGN",
        "outputId": "cddaf2b8-f110-43d5-97c5-7d3e80df2d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample files in folder: ['43148.jpg', '47963.jpg', '61664.jpg', '74849.jpg', '79333.jpg', '71931.jpg', '16303.jpg', '15517.jpg', '30797.jpg', '77430.jpg']\n",
            "Number of files in folder: 8652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if each file in the CSV exists in the folder\n",
        "data['exists_in_folder'] = data['file'].apply(lambda x: os.path.exists(os.path.join(images_folder, x)))\n",
        "\n",
        "# Display the count of existing and missing files\n",
        "print(data['exists_in_folder'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhut8eXnJMlO",
        "outputId": "5561418c-10c9-4193-8866-e92a80f3dfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exists_in_folder\n",
            "False    8781\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique file names from the CSV\n",
        "csv_files = data['file'].unique()\n",
        "print(f\"Sample file names in CSV: {csv_files[:10]}\")\n",
        "print(f\"Total unique files in CSV: {len(csv_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKR5lJAEKEsk",
        "outputId": "8dfb8bdd-6251-448b-c6ac-9a5fa178db25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample file names in CSV: ['27327' '63584' '35860' '83767' '66866' '46466' '77714' '19719' '81363'\n",
            " '82832']\n",
            "Total unique files in CSV: 8781\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract unique file names from the folder\n",
        "folder_files = os.listdir(images_folder)\n",
        "print(f\"Sample file names in folder: {folder_files[:10]}\")\n",
        "print(f\"Total files in folder: {len(folder_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWFj16VQKJjp",
        "outputId": "16c34c43-0e1c-48b8-bea3-1fcf6841806b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample file names in folder: ['43148.jpg', '47963.jpg', '61664.jpg', '74849.jpg', '79333.jpg', '71931.jpg', '16303.jpg', '15517.jpg', '30797.jpg', '77430.jpg']\n",
            "Total files in folder: 8652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the '.jpg' extension to the file names in the CSV\n",
        "data['file'] = data['file'].astype(str) + '.jpg'\n",
        "\n",
        "# Display a sample of the updated file names\n",
        "print(data['file'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXgFrBmUKcBj",
        "outputId": "a52afa0f-26ef-47a5-961a-81be79ad56c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    27327.jpg\n",
            "1    63584.jpg\n",
            "2    35860.jpg\n",
            "3    83767.jpg\n",
            "4    66866.jpg\n",
            "Name: file, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recheck if files exist in the folder\n",
        "data['exists_in_folder'] = data['file'].apply(lambda x: os.path.exists(os.path.join(images_folder, x)))\n",
        "\n",
        "# Display the count of existing and missing files\n",
        "print(data['exists_in_folder'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAMxKtbZKd30",
        "outputId": "18215a64-4b60-4f68-97ed-05fe0bb8711f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "exists_in_folder\n",
            "True     7686\n",
            "False    1095\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows for missing files\n",
        "missing_files = data[~data['exists_in_folder']]\n",
        "\n",
        "# Save the missing file names to a CSV\n",
        "missing_files[['file']].to_csv('/content/drive/MyDrive/Lectures/missing_files_log.csv', index=False)\n",
        "print(\"Missing files logged to 'missing_files_log.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muI59elBKqBn",
        "outputId": "8e6d12cc-fe26-43dd-c050-c34f1c2cfc96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing files logged to 'missing_files_log.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter valid rows\n",
        "valid_data = data[data['exists_in_folder']].reset_index(drop=True)\n",
        "\n",
        "# Display the number of valid rows and a sample\n",
        "print(f\"Number of valid rows: {len(valid_data)}\")\n",
        "print(valid_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePX-99XUKsAv",
        "outputId": "57eab25f-ebf0-43f1-940a-c957754f7609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of valid rows: 7686\n",
            "        file  age  gender  race  service_test  exists_in_folder\n",
            "0  27327.jpg    1       1     2         False              True\n",
            "1  63584.jpg    0       0     1         False              True\n",
            "2  35860.jpg    6       0     4          True              True\n",
            "3  83767.jpg    4       1     2          True              True\n",
            "4  66866.jpg    1       0     3         False              True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add full file paths\n",
        "valid_data['file_path'] = valid_data['file'].apply(lambda x: os.path.join(images_folder, x))\n",
        "\n",
        "# Display a sample of the updated dataset\n",
        "print(valid_data[['file_path', 'age', 'gender', 'race']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXMLTICaKvJg",
        "outputId": "24762513-e3c7-46ba-8d30-560e989cf735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                           file_path  age  gender  race\n",
            "0  /content/drive/MyDrive/Lectures/Train select/2...    1       1     2\n",
            "1  /content/drive/MyDrive/Lectures/Train select/6...    0       0     1\n",
            "2  /content/drive/MyDrive/Lectures/Train select/3...    6       0     4\n",
            "3  /content/drive/MyDrive/Lectures/Train select/8...    4       1     2\n",
            "4  /content/drive/MyDrive/Lectures/Train select/6...    1       0     3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define image paths and labels\n",
        "image_paths = valid_data['file_path'].values\n",
        "labels = valid_data[['age', 'gender', 'race']].values\n",
        "\n",
        "# Function to load and preprocess images\n",
        "def load_image(file_path, label):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)  # Decode as RGB\n",
        "    img = tf.image.resize(img, (224, 224))  # Resize to match EfficientNet input\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img, label\n",
        "\n",
        "# Create a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
        "dataset = dataset.map(load_image).batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "bSGgcAgfKymn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split image paths and labels\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    image_paths, labels, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
        "train_dataset = train_dataset.map(load_image).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, val_labels))\n",
        "val_dataset = val_dataset.map(load_image).batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "lY7twXaTK6EM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the base model with pre-trained weights\n",
        "base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')\n",
        "\n",
        "# Freeze the base model to retain pre-trained weights during initial training\n",
        "base_model.trainable = False\n",
        "\n",
        "# Build the full model\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(3, activation='softmax')  # Adjust for your labels (age, gender, race)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIOYViL6LAxV",
        "outputId": "d611b149-8d6f-4165-b955-aca7f0d80f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16705208/16705208 [==============================] - 0s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " efficientnetb0 (Functional  (None, 1280)              4049571   \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               327936    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4378278 (16.70 MB)\n",
            "Trainable params: 328707 (1.25 MB)\n",
            "Non-trainable params: 4049571 (15.45 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "# Define the input\n",
        "inputs = Input(shape=(224, 224, 3))\n",
        "\n",
        "# Base model (EfficientNetB0)\n",
        "base_model = EfficientNetB0(include_top=False, input_shape=(224, 224, 3), pooling='avg', weights='imagenet')(inputs)\n",
        "\n",
        "# Age group output\n",
        "age_output = Dense(10, activation='softmax', name='age_output')(base_model)  # Adjust for 10 age groups\n",
        "\n",
        "# Gender output\n",
        "gender_output = Dense(2, activation='softmax', name='gender_output')(base_model)  # Binary classification\n",
        "\n",
        "# Race output\n",
        "race_output = Dense(7, activation='softmax', name='race_output')(base_model)  # Adjust for 7 race categories\n",
        "\n",
        "# Create the multi-output model\n",
        "model = Model(inputs=inputs, outputs=[age_output, gender_output, race_output])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={\n",
        "        'age_output': 'categorical_crossentropy',\n",
        "        'gender_output': 'categorical_crossentropy',\n",
        "        'race_output': 'categorical_crossentropy',\n",
        "    },\n",
        "    metrics={\n",
        "        'age_output': 'accuracy',\n",
        "        'gender_output': 'accuracy',\n",
        "        'race_output': 'accuracy',\n",
        "    }\n",
        ")\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQqJrmBTLt-U",
        "outputId": "bb3b8804-fecf-4d68-d8a8-25db85f63289"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " efficientnetb0 (Functional  (None, 1280)                 4049571   ['input_2[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " age_output (Dense)          (None, 10)                   12810     ['efficientnetb0[0][0]']      \n",
            "                                                                                                  \n",
            " gender_output (Dense)       (None, 2)                    2562      ['efficientnetb0[0][0]']      \n",
            "                                                                                                  \n",
            " race_output (Dense)         (None, 7)                    8967      ['efficientnetb0[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4073910 (15.54 MB)\n",
            "Trainable params: 4031887 (15.38 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# One-hot encode labels\n",
        "age_labels = to_categorical(valid_data['age'], num_classes=10)      # Adjust for the number of age groups\n",
        "gender_labels = to_categorical(valid_data['gender'], num_classes=2) # Binary classification for gender\n",
        "race_labels = to_categorical(valid_data['race'], num_classes=7)     # Adjust for the number of race categories\n",
        "\n",
        "# Combine labels into a list\n",
        "labels = [age_labels, gender_labels, race_labels]\n"
      ],
      "metadata": {
        "id": "_qN1cyZUL5kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair image paths with corresponding labels\n",
        "paired_labels = list(zip(age_labels, gender_labels, race_labels))\n"
      ],
      "metadata": {
        "id": "iD5iin3PMMe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split image paths and paired labels\n",
        "train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "    image_paths, paired_labels, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "cnRHPw-HMN2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the labels for training and validation\n",
        "train_age_labels, train_gender_labels, train_race_labels = zip(*train_labels)\n",
        "val_age_labels, val_gender_labels, val_race_labels = zip(*val_labels)\n",
        "\n",
        "# Convert labels to arrays\n",
        "train_labels = [list(train_age_labels), list(train_gender_labels), list(train_race_labels)]\n",
        "val_labels = [list(val_age_labels), list(val_gender_labels), list(val_race_labels)]\n"
      ],
      "metadata": {
        "id": "Ow_iT6jWMQ9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and preprocess images\n",
        "def load_image(file_path, labels):\n",
        "    img = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, (224, 224))  # Resize to match EfficientNet input\n",
        "    img = img / 255.0  # Normalize to [0, 1]\n",
        "    return img, labels\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_paths, tuple(train_labels)))\n",
        "train_dataset = train_dataset.map(load_image).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_paths, tuple(val_labels)))\n",
        "val_dataset = val_dataset.map(load_image).batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "id": "D86rsXEyMTnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=40,\n",
        "    validation_data=val_dataset\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "-j4YksM2MWXy",
        "outputId": "8b54ecd8-5253-4b43-fa2f-b7c1fc755c8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "193/193 [==============================] - 378s 2s/step - loss: 3.7167 - age_output_loss: 1.5803 - gender_output_loss: 0.5574 - race_output_loss: 1.5790 - age_output_accuracy: 0.3453 - gender_output_accuracy: 0.6970 - race_output_accuracy: 0.3746 - val_loss: 5.9362 - val_age_output_loss: 2.6635 - val_gender_output_loss: 0.6930 - val_race_output_loss: 2.5798 - val_age_output_accuracy: 0.1216 - val_gender_output_accuracy: 0.5169 - val_race_output_accuracy: 0.1521\n",
            "Epoch 2/40\n",
            "193/193 [==============================] - 235s 1s/step - loss: 2.7418 - age_output_loss: 1.1957 - gender_output_loss: 0.3724 - race_output_loss: 1.1738 - age_output_accuracy: 0.5067 - gender_output_accuracy: 0.8247 - race_output_accuracy: 0.5488 - val_loss: 5.4793 - val_age_output_loss: 2.5706 - val_gender_output_loss: 0.7168 - val_race_output_loss: 2.1919 - val_age_output_accuracy: 0.1294 - val_gender_output_accuracy: 0.4844 - val_race_output_accuracy: 0.1469\n",
            "Epoch 3/40\n",
            "193/193 [==============================] - 229s 1s/step - loss: 2.0487 - age_output_loss: 0.9331 - gender_output_loss: 0.2527 - race_output_loss: 0.8628 - age_output_accuracy: 0.6204 - gender_output_accuracy: 0.8907 - race_output_accuracy: 0.6789 - val_loss: 6.1031 - val_age_output_loss: 2.9757 - val_gender_output_loss: 0.7107 - val_race_output_loss: 2.4167 - val_age_output_accuracy: 0.1008 - val_gender_output_accuracy: 0.4844 - val_race_output_accuracy: 0.1469\n",
            "Epoch 4/40\n",
            "193/193 [==============================] - 228s 1s/step - loss: 1.6114 - age_output_loss: 0.7643 - gender_output_loss: 0.2013 - race_output_loss: 0.6457 - age_output_accuracy: 0.6908 - gender_output_accuracy: 0.9120 - race_output_accuracy: 0.7495 - val_loss: 7.5286 - val_age_output_loss: 3.1695 - val_gender_output_loss: 0.7433 - val_race_output_loss: 3.6157 - val_age_output_accuracy: 0.1216 - val_gender_output_accuracy: 0.4850 - val_race_output_accuracy: 0.1469\n",
            "Epoch 5/40\n",
            "193/193 [==============================] - 228s 1s/step - loss: 1.2691 - age_output_loss: 0.6088 - gender_output_loss: 0.1657 - race_output_loss: 0.4946 - age_output_accuracy: 0.7614 - gender_output_accuracy: 0.9309 - race_output_accuracy: 0.8198 - val_loss: 5.7940 - val_age_output_loss: 2.5599 - val_gender_output_loss: 0.9889 - val_race_output_loss: 2.2453 - val_age_output_accuracy: 0.1365 - val_gender_output_accuracy: 0.5228 - val_race_output_accuracy: 0.1573\n",
            "Epoch 6/40\n",
            "193/193 [==============================] - 229s 1s/step - loss: 0.9962 - age_output_loss: 0.4695 - gender_output_loss: 0.1329 - race_output_loss: 0.3938 - age_output_accuracy: 0.8234 - gender_output_accuracy: 0.9460 - race_output_accuracy: 0.8521 - val_loss: 5.9426 - val_age_output_loss: 2.6868 - val_gender_output_loss: 0.8619 - val_race_output_loss: 2.3939 - val_age_output_accuracy: 0.1534 - val_gender_output_accuracy: 0.5104 - val_race_output_accuracy: 0.1560\n",
            "Epoch 7/40\n",
            "193/193 [==============================] - 228s 1s/step - loss: 0.7900 - age_output_loss: 0.3803 - gender_output_loss: 0.1125 - race_output_loss: 0.2972 - age_output_accuracy: 0.8645 - gender_output_accuracy: 0.9562 - race_output_accuracy: 0.8970 - val_loss: 6.6621 - val_age_output_loss: 2.6356 - val_gender_output_loss: 0.8397 - val_race_output_loss: 3.1867 - val_age_output_accuracy: 0.1216 - val_gender_output_accuracy: 0.5085 - val_race_output_accuracy: 0.1554\n",
            "Epoch 8/40\n",
            "193/193 [==============================] - 229s 1s/step - loss: 0.5938 - age_output_loss: 0.2780 - gender_output_loss: 0.0984 - race_output_loss: 0.2174 - age_output_accuracy: 0.9024 - gender_output_accuracy: 0.9628 - race_output_accuracy: 0.9247 - val_loss: 323.4724 - val_age_output_loss: 147.1455 - val_gender_output_loss: 47.8407 - val_race_output_loss: 128.4862 - val_age_output_accuracy: 0.1281 - val_gender_output_accuracy: 0.5195 - val_race_output_accuracy: 0.1489\n",
            "Epoch 9/40\n",
            "193/193 [==============================] - 226s 1s/step - loss: 0.5009 - age_output_loss: 0.2171 - gender_output_loss: 0.0895 - race_output_loss: 0.1944 - age_output_accuracy: 0.9249 - gender_output_accuracy: 0.9645 - race_output_accuracy: 0.9322 - val_loss: 118.6708 - val_age_output_loss: 56.7477 - val_gender_output_loss: 20.8731 - val_race_output_loss: 41.0500 - val_age_output_accuracy: 0.1339 - val_gender_output_accuracy: 0.5150 - val_race_output_accuracy: 0.1339\n",
            "Epoch 10/40\n",
            "193/193 [==============================] - 229s 1s/step - loss: 0.4076 - age_output_loss: 0.1897 - gender_output_loss: 0.0650 - race_output_loss: 0.1530 - age_output_accuracy: 0.9327 - gender_output_accuracy: 0.9759 - race_output_accuracy: 0.9489 - val_loss: 4977.7959 - val_age_output_loss: 2018.7019 - val_gender_output_loss: 755.0917 - val_race_output_loss: 2204.0015 - val_age_output_accuracy: 0.1177 - val_gender_output_accuracy: 0.5072 - val_race_output_accuracy: 0.1326\n",
            "Epoch 11/40\n",
            "193/193 [==============================] - 228s 1s/step - loss: 0.3674 - age_output_loss: 0.1645 - gender_output_loss: 0.0621 - race_output_loss: 0.1408 - age_output_accuracy: 0.9403 - gender_output_accuracy: 0.9756 - race_output_accuracy: 0.9504 - val_loss: 11.4546 - val_age_output_loss: 3.6401 - val_gender_output_loss: 0.6943 - val_race_output_loss: 7.1203 - val_age_output_accuracy: 0.1352 - val_gender_output_accuracy: 0.5143 - val_race_output_accuracy: 0.1469\n",
            "Epoch 12/40\n",
            "193/193 [==============================] - 229s 1s/step - loss: 0.3522 - age_output_loss: 0.1565 - gender_output_loss: 0.0496 - race_output_loss: 0.1461 - age_output_accuracy: 0.9463 - gender_output_accuracy: 0.9793 - race_output_accuracy: 0.9514 - val_loss: 130.3256 - val_age_output_loss: 68.7084 - val_gender_output_loss: 10.1442 - val_race_output_loss: 51.4729 - val_age_output_accuracy: 0.1242 - val_gender_output_accuracy: 0.4863 - val_race_output_accuracy: 0.1424\n",
            "Epoch 13/40\n",
            "103/193 [===============>..............] - ETA: 1:40 - loss: 0.3362 - age_output_loss: 0.1388 - gender_output_loss: 0.0583 - race_output_loss: 0.1391 - age_output_accuracy: 0.9512 - gender_output_accuracy: 0.9769 - race_output_accuracy: 0.9518"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-555304f67c4f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNw96m6vYUz_",
        "outputId": "3450fb6c-f35d-4369-bbea-47399e503059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " efficientnetb0 (Functional  (None, 1280)                 4049571   ['input_2[0][0]']             \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " age_output (Dense)          (None, 10)                   12810     ['efficientnetb0[0][0]']      \n",
            "                                                                                                  \n",
            " gender_output (Dense)       (None, 2)                    2562      ['efficientnetb0[0][0]']      \n",
            "                                                                                                  \n",
            " race_output (Dense)         (None, 7)                    8967      ['efficientnetb0[0][0]']      \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4073910 (15.54 MB)\n",
            "Trainable params: 4031887 (15.38 MB)\n",
            "Non-trainable params: 42023 (164.16 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Lectures/interrupted_model.h5')\n",
        "print(\"Model saved successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cz1ndYYXQs",
        "outputId": "5d954974-8c78-4f7b-9fd4-f6b69a30a34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss={\n",
        "        'age_output': 'categorical_crossentropy',\n",
        "        'gender_output': 'categorical_crossentropy',\n",
        "        'race_output': 'categorical_crossentropy',\n",
        "    },\n",
        "    metrics={\n",
        "        'age_output': 'accuracy',\n",
        "        'gender_output': 'accuracy',\n",
        "        'race_output': 'accuracy',\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "uX05UbC2ZHHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "    layer.trainable = True\n"
      ],
      "metadata": {
        "id": "yH4sq7_ZZIp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
        "    loss={\n",
        "        'age_output': 'categorical_crossentropy',\n",
        "        'gender_output': 'categorical_crossentropy',\n",
        "        'race_output': 'categorical_crossentropy',\n",
        "    },\n",
        "    metrics={\n",
        "        'age_output': 'accuracy',\n",
        "        'gender_output': 'accuracy',\n",
        "        'race_output': 'accuracy',\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "NYEj44c5ZQjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10,  # Fewer epochs for fine-tuning\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNxmygV3ZT5X",
        "outputId": "eb7797c0-273e-4a05-cdc1-587049911520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "193/193 [==============================] - 259s 1s/step - loss: 0.2927 - age_output_loss: 0.1248 - gender_output_loss: 0.0494 - race_output_loss: 0.1185 - age_output_accuracy: 0.9562 - gender_output_accuracy: 0.9811 - race_output_accuracy: 0.9585 - val_loss: 6.2374 - val_age_output_loss: 2.6223 - val_gender_output_loss: 0.7631 - val_race_output_loss: 2.8520 - val_age_output_accuracy: 0.3108 - val_gender_output_accuracy: 0.7198 - val_race_output_accuracy: 0.3511 - lr: 1.0000e-05\n",
            "Epoch 2/10\n",
            "193/193 [==============================] - 232s 1s/step - loss: 0.2121 - age_output_loss: 0.0936 - gender_output_loss: 0.0381 - race_output_loss: 0.0804 - age_output_accuracy: 0.9671 - gender_output_accuracy: 0.9852 - race_output_accuracy: 0.9743 - val_loss: 5.6459 - val_age_output_loss: 2.5814 - val_gender_output_loss: 0.7044 - val_race_output_loss: 2.3602 - val_age_output_accuracy: 0.4408 - val_gender_output_accuracy: 0.8296 - val_race_output_accuracy: 0.4896 - lr: 1.0000e-05\n",
            "Epoch 3/10\n",
            "193/193 [==============================] - 232s 1s/step - loss: 0.1685 - age_output_loss: 0.0744 - gender_output_loss: 0.0277 - race_output_loss: 0.0664 - age_output_accuracy: 0.9782 - gender_output_accuracy: 0.9912 - race_output_accuracy: 0.9780 - val_loss: 5.4219 - val_age_output_loss: 2.4528 - val_gender_output_loss: 0.6799 - val_race_output_loss: 2.2892 - val_age_output_accuracy: 0.4636 - val_gender_output_accuracy: 0.8375 - val_race_output_accuracy: 0.5124 - lr: 1.0000e-05\n",
            "Epoch 4/10\n",
            "193/193 [==============================] - 233s 1s/step - loss: 0.1404 - age_output_loss: 0.0666 - gender_output_loss: 0.0236 - race_output_loss: 0.0503 - age_output_accuracy: 0.9806 - gender_output_accuracy: 0.9915 - race_output_accuracy: 0.9862 - val_loss: 5.3545 - val_age_output_loss: 2.4262 - val_gender_output_loss: 0.6735 - val_race_output_loss: 2.2548 - val_age_output_accuracy: 0.4545 - val_gender_output_accuracy: 0.8459 - val_race_output_accuracy: 0.5046 - lr: 1.0000e-05\n",
            "Epoch 5/10\n",
            "193/193 [==============================] - 231s 1s/step - loss: 0.1163 - age_output_loss: 0.0538 - gender_output_loss: 0.0192 - race_output_loss: 0.0433 - age_output_accuracy: 0.9863 - gender_output_accuracy: 0.9943 - race_output_accuracy: 0.9893 - val_loss: 5.2784 - val_age_output_loss: 2.4034 - val_gender_output_loss: 0.6708 - val_race_output_loss: 2.2043 - val_age_output_accuracy: 0.4564 - val_gender_output_accuracy: 0.8381 - val_race_output_accuracy: 0.5117 - lr: 1.0000e-05\n",
            "Epoch 6/10\n",
            "193/193 [==============================] - 230s 1s/step - loss: 0.1046 - age_output_loss: 0.0454 - gender_output_loss: 0.0183 - race_output_loss: 0.0409 - age_output_accuracy: 0.9902 - gender_output_accuracy: 0.9933 - race_output_accuracy: 0.9885 - val_loss: 5.2946 - val_age_output_loss: 2.4065 - val_gender_output_loss: 0.6708 - val_race_output_loss: 2.2173 - val_age_output_accuracy: 0.4649 - val_gender_output_accuracy: 0.8446 - val_race_output_accuracy: 0.5169 - lr: 1.0000e-05\n",
            "Epoch 7/10\n",
            "193/193 [==============================] - 231s 1s/step - loss: 0.0932 - age_output_loss: 0.0423 - gender_output_loss: 0.0163 - race_output_loss: 0.0346 - age_output_accuracy: 0.9907 - gender_output_accuracy: 0.9950 - race_output_accuracy: 0.9928 - val_loss: 5.1720 - val_age_output_loss: 2.3450 - val_gender_output_loss: 0.6442 - val_race_output_loss: 2.1829 - val_age_output_accuracy: 0.4636 - val_gender_output_accuracy: 0.8446 - val_race_output_accuracy: 0.5286 - lr: 1.0000e-05\n",
            "Epoch 8/10\n",
            "193/193 [==============================] - 229s 1s/step - loss: 0.0822 - age_output_loss: 0.0369 - gender_output_loss: 0.0137 - race_output_loss: 0.0316 - age_output_accuracy: 0.9924 - gender_output_accuracy: 0.9969 - race_output_accuracy: 0.9932 - val_loss: 5.2449 - val_age_output_loss: 2.4205 - val_gender_output_loss: 0.6611 - val_race_output_loss: 2.1633 - val_age_output_accuracy: 0.4434 - val_gender_output_accuracy: 0.8381 - val_race_output_accuracy: 0.5169 - lr: 1.0000e-05\n",
            "Epoch 9/10\n",
            "193/193 [==============================] - 231s 1s/step - loss: 0.0748 - age_output_loss: 0.0346 - gender_output_loss: 0.0114 - race_output_loss: 0.0288 - age_output_accuracy: 0.9937 - gender_output_accuracy: 0.9979 - race_output_accuracy: 0.9937 - val_loss: 5.3339 - val_age_output_loss: 2.4785 - val_gender_output_loss: 0.6839 - val_race_output_loss: 2.1715 - val_age_output_accuracy: 0.4291 - val_gender_output_accuracy: 0.8290 - val_race_output_accuracy: 0.5189 - lr: 1.0000e-05\n",
            "Epoch 10/10\n",
            "193/193 [==============================] - 231s 1s/step - loss: 0.0671 - age_output_loss: 0.0314 - gender_output_loss: 0.0112 - race_output_loss: 0.0244 - age_output_accuracy: 0.9938 - gender_output_accuracy: 0.9977 - race_output_accuracy: 0.9954 - val_loss: 5.4179 - val_age_output_loss: 2.5221 - val_gender_output_loss: 0.6940 - val_race_output_loss: 2.2018 - val_age_output_accuracy: 0.4233 - val_gender_output_accuracy: 0.8264 - val_race_output_accuracy: 0.5137 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Lectures/fine_tuned_model_epoch10.h5')\n",
        "print(\"Model saved as HDF5 format!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0kqYATOkJfL",
        "outputId": "64ce7964-02d7-4289-dcb1-c2ae580bd127"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as HDF5 format!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Extract model weights and architecture\n",
        "model_data = {\n",
        "    'model_config': model.to_json(),  # Save model architecture\n",
        "    'model_weights': model.get_weights()  # Save model weights\n",
        "}\n",
        "\n",
        "# Save the model data to a .pkl file\n",
        "with open('/content/drive/MyDrive/Lectures/fine_tuned_model_epoch10.pkl', 'wb') as f:\n",
        "    pickle.dump(model_data, f)\n",
        "\n",
        "print(\"Model saved as a .pkl file!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uE6PYBlDlfbt",
        "outputId": "49c8fa75-90e3-48f2-e418-58b8849c99e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved as a .pkl file!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of labels in the training data\n",
        "print(valid_data['age'].value_counts())   # Distribution of age groups\n",
        "print(valid_data['race'].value_counts())  # Distribution of race classes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmX-OWvIljR0",
        "outputId": "35f60a47-ce75-4e49-8873-dad783e137b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age\n",
            "3    991\n",
            "4    970\n",
            "1    968\n",
            "7    966\n",
            "5    962\n",
            "6    956\n",
            "2    944\n",
            "0    929\n",
            "Name: count, dtype: int64\n",
            "race\n",
            "1    1120\n",
            "3    1111\n",
            "6    1105\n",
            "5    1105\n",
            "0    1104\n",
            "2    1098\n",
            "4    1043\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "print(valid_data.head())\n",
        "\n",
        "# Check the unique values for age and race\n",
        "print(\"Unique age labels:\", valid_data['age'].unique())\n",
        "print(\"Unique race labels:\", valid_data['race'].unique())\n"
      ],
      "metadata": {
        "id": "_gdDxF0qpXpm",
        "outputId": "92b398d9-3eb0-414d-9b8b-6c16acd92e20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        file  age  gender  race  service_test  exists_in_folder  \\\n",
            "0  27327.jpg    1       1     2         False              True   \n",
            "1  63584.jpg    0       0     1         False              True   \n",
            "2  35860.jpg    6       0     4          True              True   \n",
            "3  83767.jpg    4       1     2          True              True   \n",
            "4  66866.jpg    1       0     3         False              True   \n",
            "\n",
            "                                           file_path  \n",
            "0  /content/drive/MyDrive/Lectures/Train select/2...  \n",
            "1  /content/drive/MyDrive/Lectures/Train select/6...  \n",
            "2  /content/drive/MyDrive/Lectures/Train select/3...  \n",
            "3  /content/drive/MyDrive/Lectures/Train select/8...  \n",
            "4  /content/drive/MyDrive/Lectures/Train select/6...  \n",
            "Unique age labels: [1 0 6 4 7 2 5 3]\n",
            "Unique race labels: [2 1 4 3 0 6 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXgo9zPwpbR-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}